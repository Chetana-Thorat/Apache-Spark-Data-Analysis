
# ğŸ Apache Spark IPL Data Analysis

---

## ğŸš€ Overview

This project performs large-scale data analysis on **Indian Premier League (IPL)** datasets using **Apache Spark** on **Azure Databricks**. It showcases how distributed computing can be applied to derive insights from real-world cricket data.

- **Goal:** Use PySpark to analyze IPL data (till 2017) covering teams, matches, players, and deliveries.
- **Platform:** Azure Databricks
- **Tech Stack:** Apache Spark Â· PySpark Â· Databricks Â· Python Â· CSV

---

## ğŸ›  Technologies Used

- **Apache Spark (PySpark)** â€“ Distributed processing of large datasets
- **Azure Databricks** â€“ Cloud environment for Spark development
- **Python** â€“ For writing Spark logic and transformations
- **CSV Files** â€“ Used as the input IPL dataset format
- **Git & GitHub** â€“ Version control and project hosting

---

## ğŸ“ Project Structure

```

apache\_spark\_project/
â”œâ”€â”€ dataset/                              # IPL CSV files
â”‚   â”œâ”€â”€ Ball\_By\_Ball.csv
â”‚   â”œâ”€â”€ Match.csv
â”‚   â”œâ”€â”€ Player.csv
â”‚   â”œâ”€â”€ Player\_match.csv
â”‚   â””â”€â”€ Team.csv
â”‚
â”œâ”€â”€ IPL\_data\_analysis\_spark.ipynb         # Main Databricks notebook with PySpark logic
â””â”€â”€ README.md                             # Documentation

```

---

## ğŸ“Œ How It Works

1. **Data Loading:** Load all CSV files as Spark DataFrames using `spark.read.csv()`.
2. **Exploration:** Inspect schemas, clean missing values, and understand data distributions.
3. **Analysis:** Perform analytical queries using `groupBy`, `join`, `agg`, `filter`, etc.
4. **Insights Derived:**
   - Top-performing players and teams
   - Toss-winning impact
   - Venue-based match trends
   - Most common dismissal types
   - Player contributions by season

---

## ğŸ“Š Dataset Used

This dataset is publicly available and contains comprehensive IPL match data till 2017.  
ğŸ”— [Source: IPL Data on data.world](https://data.world/mkhuzaima/ipl-data-till-2017)

Included files:
- `Ball_By_Ball.csv` â€“ Each delivery across all IPL matches
- `Match.csv` â€“ Match metadata
- `Player.csv` â€“ Player details
- `Player_match.csv` â€“ Player participation records
- `Team.csv` â€“ Team names and codes

---

## ğŸ§  Learnings

- Hands-on experience with PySpark and lazy evaluation
- Schema inference, null handling, and column manipulation
- Performing joins, aggregates, and filters at scale
- Real-time development and visualization in Databricks
- End-to-end pipeline from data import to insight generation

---

## ğŸ™Œ Author

**Chetana Thorat**  
ğŸ“§ thoratchetana8@gmail.com  
ğŸ“ Master's in Data Science @ Indiana University Bloomington  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/chetana-thorat) | [GitHub](https://github.com/Chetana-Thorat)

---

## ğŸ“œ License

This project is open source under the [MIT License](LICENSE).
```
